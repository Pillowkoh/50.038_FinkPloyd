{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC data shape: (1802, 1920, 20)\n",
      "Labels shape: (1802, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import librosa\n",
    "\n",
    "with open('mfcc_data.npy', 'rb') as f:\n",
    "    mfcc_data = np.load(f)\n",
    "print(f'MFCC data shape: {mfcc_data.shape}')\n",
    "\n",
    "label_path = 'deam-dataset/DEAM_Annotations/annotations/annotations averaged per song/song_level/';\n",
    "labels_1_2000 = pd.read_csv(os.path.join(label_path, 'static_annotations_averaged_songs_1_2000.csv'))\n",
    "labels_2000_2058 = pd.read_csv(os.path.join(label_path,'static_annotations_averaged_songs_2000_2058.csv'))\n",
    "labels = pd.concat([labels_1_2000, labels_2000_2058], ignore_index=True, sort=False)\n",
    "labels = labels[labels_1_2000.columns]\n",
    "labels.columns = labels.columns.str.replace(' ', '')\n",
    "\n",
    "valence = labels['valence_mean'].to_numpy()\n",
    "arousal = labels['arousal_mean'].to_numpy()\n",
    "y = np.vstack([valence, arousal]).T\n",
    "print(f'Labels shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: 3D matrix representation of data(data_length, frames, coeffs), time-step size (in seconds)\n",
    "# output: 4D matrix representation of split into time-steps (data_length, n_time_steps, frames per timestep, coeffs)\n",
    "def split_timesteps(data, time_step=0.5):\n",
    "    n_frames = data.shape[1]\n",
    "    time_step_size = librosa.time_to_frames(time_step, sr=22050, hop_length=512)\n",
    "    n_time_steps = math.floor(n_frames / time_step_size)\n",
    "    \n",
    "    print(f'Total no. of frames per data point: {n_frames}')\n",
    "    print(f'No. of time steps: {n_time_steps}')\n",
    "    print(f'No. of frames per time step: {time_step_size}')\n",
    "    \n",
    "    new_data = np.empty([data.shape[0], n_time_steps, time_step_size, data.shape[2]])\n",
    "    \n",
    "    frame_idxes = np.arange(0, n_frames, time_step_size)[:n_time_steps]\n",
    "    for data_i in range(data.shape[0]):\n",
    "        data_pt = np.empty([n_time_steps, time_step_size, data.shape[2]])\n",
    "        for i, frame_idx in enumerate(frame_idxes):\n",
    "            start_frame = frame_idx\n",
    "            end_frame = frame_idx + time_step_size\n",
    "            if end_frame > n_frames: \n",
    "                break\n",
    "            data_pt[i] = data[data_i][start_frame:end_frame, :]\n",
    "        new_data[data_i] = data_pt\n",
    "    return new_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of frames per data point: 1920\n",
      "No. of time steps: 91\n",
      "No. of frames per time step: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1802, 91, 21, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_mfcc = split_timesteps(mfcc_data, time_step=0.5)\n",
    "split_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "# idx = np.arange(split_mfcc.shape[0])\n",
    "# X_trn_idx, X_test_idx, y_trn, y_test = train_test_split(idx, y, test_size=0.2, random_state=23)\n",
    "# X_train_idx, X_valid_idx, y_train, y_valid = train_test_split(X_trn_idx, y_trn, test_size=0.33, random_state=23)\n",
    "\n",
    "# X_mfcc_train = split_mfcc[X_train_idx]\n",
    "# X_mfcc_valid = split_mfcc[X_valid_idx]\n",
    "# X_mfcc_test = split_mfcc[X_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "def categorize_val_arousal(data):\n",
    "    cat_data = []\n",
    "    # A: active, P: passive\n",
    "    # P: positive, N: negative\n",
    "    for point in data:\n",
    "        valence, arousal = point[0], point[1]\n",
    "        if valence >= 5 and arousal >= 5:\n",
    "            cat_data.append('AP')\n",
    "        elif valence < 5 and arousal >= 5:\n",
    "            cat_data.append('AN')\n",
    "        elif valence >= 5 and arousal < 5:\n",
    "            cat_data.append('PP')\n",
    "        elif valence < 5 and arousal < 5:\n",
    "            cat_data.append('PN')\n",
    "    return np.array(cat_data, dtype='str')\n",
    "\n",
    "idx = np.arange(split_mfcc.shape[0])\n",
    "\n",
    "sss_test = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=23)\n",
    "for train_index, test_index in sss_test.split(idx, categorize_val_arousal(y)):\n",
    "    X_trn_idx, X_test_idx = idx[train_index], idx[test_index]\n",
    "    y_trn, y_test = y[train_index], y[test_index]\n",
    "\n",
    "sss_valid = StratifiedShuffleSplit(n_splits=5, test_size=0.33, random_state=23)\n",
    "for train_index, test_index in sss_test.split(X_trn_idx, categorize_val_arousal(y_trn)):\n",
    "    X_train_idx, X_valid_idx = X_trn_idx[train_index], X_trn_idx[test_index]\n",
    "    y_train, y_valid = y_trn[train_index], y_trn[test_index]\n",
    "\n",
    "X_mfcc_train = split_mfcc[X_train_idx]\n",
    "X_mfcc_valid = split_mfcc[X_valid_idx]\n",
    "X_mfcc_test = split_mfcc[X_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, \n",
    "                                     TimeDistributed, LSTM,\n",
    "                                     Flatten, Dense, Dropout, RepeatVector, LeakyReLU,\n",
    "                                     LayerNormalization, BatchNormalization)\n",
    "\n",
    "leaky_relu = LeakyReLU(alpha=0.05)\n",
    "conv_layer = partial(Conv1D, kernel_size=4, activation=leaky_relu, padding='SAME', strides=1)\n",
    "pooling = partial(MaxPooling1D, pool_size=4, strides=4, padding='SAME')\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    TimeDistributed(LayerNormalization()),\n",
    "    TimeDistributed(conv_layer(input_shape=(1920, 20), filters=32, kernel_size=6)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=64)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=128)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=128)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(64),\n",
    "    Dense(128, activation=leaky_relu),\n",
    "    Dropout(0.3),\n",
    "    Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 4.6696 - mean_squared_error: 23.3587 - val_loss: 4.4189 - val_mean_squared_error: 20.9845\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.9628 - mean_squared_error: 17.3711 - val_loss: 3.3929 - val_mean_squared_error: 12.9684\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.7678 - mean_squared_error: 9.3908 - val_loss: 2.1153 - val_mean_squared_error: 5.8162\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.7408 - mean_squared_error: 4.3344 - val_loss: 1.2895 - val_mean_squared_error: 2.4999\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.2510 - mean_squared_error: 2.3823 - val_loss: 1.0404 - val_mean_squared_error: 1.5788\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.1469 - mean_squared_error: 2.0126 - val_loss: 0.9923 - val_mean_squared_error: 1.4207\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.1449 - mean_squared_error: 1.9792 - val_loss: 0.9804 - val_mean_squared_error: 1.3838\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.1439 - mean_squared_error: 1.9809 - val_loss: 0.9715 - val_mean_squared_error: 1.3592\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.1258 - mean_squared_error: 1.9199 - val_loss: 0.9623 - val_mean_squared_error: 1.3342\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.1159 - mean_squared_error: 1.9129 - val_loss: 0.9507 - val_mean_squared_error: 1.3038\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.0794 - mean_squared_error: 1.7861 - val_loss: 0.9332 - val_mean_squared_error: 1.2623\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0954 - mean_squared_error: 1.8071 - val_loss: 0.9164 - val_mean_squared_error: 1.2221\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0496 - mean_squared_error: 1.6954 - val_loss: 0.8950 - val_mean_squared_error: 1.1741\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0222 - mean_squared_error: 1.6077 - val_loss: 0.8857 - val_mean_squared_error: 1.1525\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0219 - mean_squared_error: 1.6151 - val_loss: 0.8492 - val_mean_squared_error: 1.0982\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0199 - mean_squared_error: 1.5973 - val_loss: 0.8296 - val_mean_squared_error: 1.0525\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9956 - mean_squared_error: 1.5591 - val_loss: 0.8723 - val_mean_squared_error: 1.1432\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.0014 - mean_squared_error: 1.5660 - val_loss: 0.8505 - val_mean_squared_error: 1.1035\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9712 - mean_squared_error: 1.4929 - val_loss: 0.8369 - val_mean_squared_error: 1.0790\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9805 - mean_squared_error: 1.5105 - val_loss: 0.8203 - val_mean_squared_error: 1.0488\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9729 - mean_squared_error: 1.4991 - val_loss: 0.8148 - val_mean_squared_error: 1.0398\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9566 - mean_squared_error: 1.4546 - val_loss: 0.8157 - val_mean_squared_error: 1.0411\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9678 - mean_squared_error: 1.4763 - val_loss: 0.8298 - val_mean_squared_error: 1.0546\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9687 - mean_squared_error: 1.4878 - val_loss: 0.8155 - val_mean_squared_error: 1.0375\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9658 - mean_squared_error: 1.4630 - val_loss: 0.8001 - val_mean_squared_error: 1.0033\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9435 - mean_squared_error: 1.3997 - val_loss: 0.8054 - val_mean_squared_error: 1.0191\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9171 - mean_squared_error: 1.3321 - val_loss: 0.8144 - val_mean_squared_error: 1.0192\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9395 - mean_squared_error: 1.3767 - val_loss: 0.7949 - val_mean_squared_error: 0.9958\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9353 - mean_squared_error: 1.3740 - val_loss: 0.8094 - val_mean_squared_error: 1.0063\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9315 - mean_squared_error: 1.3900 - val_loss: 0.7998 - val_mean_squared_error: 1.0031\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9304 - mean_squared_error: 1.3791 - val_loss: 0.8002 - val_mean_squared_error: 1.0035\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9179 - mean_squared_error: 1.3275 - val_loss: 0.7919 - val_mean_squared_error: 1.0044\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9192 - mean_squared_error: 1.3465 - val_loss: 0.7968 - val_mean_squared_error: 0.9946\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9311 - mean_squared_error: 1.3683 - val_loss: 0.7974 - val_mean_squared_error: 0.9956\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9326 - mean_squared_error: 1.3738 - val_loss: 0.8007 - val_mean_squared_error: 1.0020\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9146 - mean_squared_error: 1.3624 - val_loss: 0.7895 - val_mean_squared_error: 0.9952\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9174 - mean_squared_error: 1.3555 - val_loss: 0.8148 - val_mean_squared_error: 1.0130\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9280 - mean_squared_error: 1.3503 - val_loss: 0.7977 - val_mean_squared_error: 0.9893\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9007 - mean_squared_error: 1.2770 - val_loss: 0.7993 - val_mean_squared_error: 0.9935\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9259 - mean_squared_error: 1.3702 - val_loss: 0.7943 - val_mean_squared_error: 0.9882\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.9070 - mean_squared_error: 1.3258 - val_loss: 0.7970 - val_mean_squared_error: 0.9976\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9168 - mean_squared_error: 1.3192 - val_loss: 0.7844 - val_mean_squared_error: 0.9918\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9052 - mean_squared_error: 1.3235 - val_loss: 0.7851 - val_mean_squared_error: 0.9885\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8854 - mean_squared_error: 1.2753 - val_loss: 0.7879 - val_mean_squared_error: 0.9825\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8984 - mean_squared_error: 1.3033 - val_loss: 0.7843 - val_mean_squared_error: 0.9811\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9041 - mean_squared_error: 1.3061 - val_loss: 0.7845 - val_mean_squared_error: 0.9893\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9052 - mean_squared_error: 1.3026 - val_loss: 0.7916 - val_mean_squared_error: 0.9763\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8969 - mean_squared_error: 1.2782 - val_loss: 0.7930 - val_mean_squared_error: 0.9885\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9196 - mean_squared_error: 1.3095 - val_loss: 0.7803 - val_mean_squared_error: 0.9654\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8782 - mean_squared_error: 1.2336 - val_loss: 0.7784 - val_mean_squared_error: 0.9696\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9000 - mean_squared_error: 1.3069 - val_loss: 0.7811 - val_mean_squared_error: 0.9747\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8915 - mean_squared_error: 1.2669 - val_loss: 0.7773 - val_mean_squared_error: 0.9700\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8903 - mean_squared_error: 1.2882 - val_loss: 0.7814 - val_mean_squared_error: 0.9582\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8915 - mean_squared_error: 1.2704 - val_loss: 0.7828 - val_mean_squared_error: 0.9678\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8903 - mean_squared_error: 1.2745 - val_loss: 0.7751 - val_mean_squared_error: 0.9607\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8833 - mean_squared_error: 1.2576 - val_loss: 0.7802 - val_mean_squared_error: 0.9641\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8831 - mean_squared_error: 1.2748 - val_loss: 0.7951 - val_mean_squared_error: 0.9797\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.8789 - mean_squared_error: 1.2383 - val_loss: 0.7926 - val_mean_squared_error: 0.9941\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8723 - mean_squared_error: 1.2373 - val_loss: 0.7780 - val_mean_squared_error: 0.9653\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8798 - mean_squared_error: 1.2259 - val_loss: 0.7777 - val_mean_squared_error: 0.9464\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8983 - mean_squared_error: 1.2875 - val_loss: 0.7729 - val_mean_squared_error: 0.9479\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8862 - mean_squared_error: 1.2500 - val_loss: 0.7757 - val_mean_squared_error: 0.9498\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8812 - mean_squared_error: 1.2447 - val_loss: 0.7781 - val_mean_squared_error: 0.9496\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8764 - mean_squared_error: 1.2379 - val_loss: 0.7736 - val_mean_squared_error: 0.9367\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9005 - mean_squared_error: 1.2913 - val_loss: 0.7749 - val_mean_squared_error: 0.9552\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8762 - mean_squared_error: 1.2199 - val_loss: 0.7888 - val_mean_squared_error: 0.9879\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.8705 - mean_squared_error: 1.2120 - val_loss: 0.7756 - val_mean_squared_error: 0.9369\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8726 - mean_squared_error: 1.2204 - val_loss: 0.7905 - val_mean_squared_error: 0.9869\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.8806 - mean_squared_error: 1.2481 - val_loss: 0.7995 - val_mean_squared_error: 0.9762\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.00002)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "history = model.fit(X_mfcc_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data=(X_mfcc_valid, y_valid), \n",
    "                    batch_size=16, \n",
    "                    callbacks=early_stopping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7464 - mean_squared_error: 0.8855\n",
      "Test reg RMSE: [0.8639533762118491, 0.9410162153356972]\n",
      "Test Accuracy: 0.6260387811634349\n",
      "Confusion matrix: \n",
      "Predicted  AN   AP   PN\n",
      "Actual                 \n",
      "AN          2   26   18\n",
      "AP          3  112   15\n",
      "PN          2   23  112\n",
      "PP          0   27   21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "score = model.evaluate(X_mfcc_test, y_test)\n",
    "print(f'Test reg RMSE: {list(map(math.sqrt, score))}')\n",
    "y_pred = model.predict(X_mfcc_test)\n",
    "\n",
    "cat_y_pred = categorize_val_arousal(y_pred)\n",
    "cat_y_test = categorize_val_arousal(y_test)\n",
    "\n",
    "accuracy = accuracy_score(cat_y_test, cat_y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "pd_y_actu = pd.Series(cat_y_test, name='Actual')\n",
    "pd_y_pred = pd.Series(cat_y_pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(pd_y_actu, pd_y_pred)\n",
    "print(f'Confusion matrix: \\n{df_confusion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7791815, 5.8042803],\n",
       "       [3.7000713, 3.385582 ],\n",
       "       [5.305857 , 5.455228 ],\n",
       "       [5.6549506, 5.777587 ],\n",
       "       [4.314077 , 4.204838 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2, 6.2],\n",
       "       [5. , 2.4],\n",
       "       [5.4, 5.5],\n",
       "       [5.2, 5.2],\n",
       "       [4.7, 3.1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 2s 21ms/step - loss: 4.7713 - mean_squared_error: 24.2772 - val_loss: 4.6947 - val_mean_squared_error: 23.5338\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 4.6420 - mean_squared_error: 23.0738 - val_loss: 4.5447 - val_mean_squared_error: 22.1486\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 4.4627 - mean_squared_error: 21.4484 - val_loss: 4.3384 - val_mean_squared_error: 20.3195\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 4.2281 - mean_squared_error: 19.4292 - val_loss: 4.0747 - val_mean_squared_error: 18.1081\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 3.9354 - mean_squared_error: 17.0515 - val_loss: 3.7446 - val_mean_squared_error: 15.5368\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 3.5764 - mean_squared_error: 14.3961 - val_loss: 3.3683 - val_mean_squared_error: 12.8690\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 3.1887 - mean_squared_error: 11.8372 - val_loss: 2.9836 - val_mean_squared_error: 10.4311\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 2.8220 - mean_squared_error: 9.6365 - val_loss: 2.6025 - val_mean_squared_error: 8.2667\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 2.4337 - mean_squared_error: 7.5514 - val_loss: 2.2383 - val_mean_squared_error: 6.4337\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 2.1032 - mean_squared_error: 5.9791 - val_loss: 1.9280 - val_mean_squared_error: 5.0037\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.8258 - mean_squared_error: 4.7301 - val_loss: 1.6752 - val_mean_squared_error: 3.9281\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.6190 - mean_squared_error: 3.8858 - val_loss: 1.4764 - val_mean_squared_error: 3.1404\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.4681 - mean_squared_error: 3.2115 - val_loss: 1.3258 - val_mean_squared_error: 2.5682\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 1.3315 - mean_squared_error: 2.6879 - val_loss: 1.2168 - val_mean_squared_error: 2.1728\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.2604 - mean_squared_error: 2.4349 - val_loss: 1.1392 - val_mean_squared_error: 1.8981\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.2310 - mean_squared_error: 2.2725 - val_loss: 1.0876 - val_mean_squared_error: 1.7192\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.2032 - mean_squared_error: 2.1601 - val_loss: 1.0527 - val_mean_squared_error: 1.6026\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1589 - mean_squared_error: 1.9968 - val_loss: 1.0289 - val_mean_squared_error: 1.5304\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1653 - mean_squared_error: 2.0449 - val_loss: 1.0160 - val_mean_squared_error: 1.4924\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1324 - mean_squared_error: 1.9195 - val_loss: 1.0076 - val_mean_squared_error: 1.4687\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1542 - mean_squared_error: 2.0007 - val_loss: 1.0012 - val_mean_squared_error: 1.4521\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1486 - mean_squared_error: 1.9839 - val_loss: 0.9972 - val_mean_squared_error: 1.4439\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1283 - mean_squared_error: 1.9013 - val_loss: 0.9937 - val_mean_squared_error: 1.4353\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1034 - mean_squared_error: 1.8436 - val_loss: 0.9886 - val_mean_squared_error: 1.4233\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1212 - mean_squared_error: 1.9123 - val_loss: 0.9850 - val_mean_squared_error: 1.4154\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1015 - mean_squared_error: 1.8185 - val_loss: 0.9817 - val_mean_squared_error: 1.4077\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1154 - mean_squared_error: 1.8562 - val_loss: 0.9799 - val_mean_squared_error: 1.4030\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1297 - mean_squared_error: 1.9108 - val_loss: 0.9784 - val_mean_squared_error: 1.3978\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1137 - mean_squared_error: 1.8874 - val_loss: 0.9776 - val_mean_squared_error: 1.3937\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1133 - mean_squared_error: 1.8452 - val_loss: 0.9732 - val_mean_squared_error: 1.3834\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1076 - mean_squared_error: 1.8287 - val_loss: 0.9695 - val_mean_squared_error: 1.3744\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1112 - mean_squared_error: 1.8559 - val_loss: 0.9643 - val_mean_squared_error: 1.3624\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0937 - mean_squared_error: 1.8186 - val_loss: 0.9589 - val_mean_squared_error: 1.3510\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0807 - mean_squared_error: 1.7822 - val_loss: 0.9564 - val_mean_squared_error: 1.3417\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.1049 - mean_squared_error: 1.8127 - val_loss: 0.9504 - val_mean_squared_error: 1.3257\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0997 - mean_squared_error: 1.8223 - val_loss: 0.9501 - val_mean_squared_error: 1.3209\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0812 - mean_squared_error: 1.7566 - val_loss: 0.9422 - val_mean_squared_error: 1.3019\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0690 - mean_squared_error: 1.7163 - val_loss: 0.9309 - val_mean_squared_error: 1.2763\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0668 - mean_squared_error: 1.7215 - val_loss: 0.9239 - val_mean_squared_error: 1.2583\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0598 - mean_squared_error: 1.7061 - val_loss: 0.9154 - val_mean_squared_error: 1.2382\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0503 - mean_squared_error: 1.6582 - val_loss: 0.9049 - val_mean_squared_error: 1.2147\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0495 - mean_squared_error: 1.6807 - val_loss: 0.8989 - val_mean_squared_error: 1.2008\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0570 - mean_squared_error: 1.6661 - val_loss: 0.8892 - val_mean_squared_error: 1.1789\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0300 - mean_squared_error: 1.6214 - val_loss: 0.8737 - val_mean_squared_error: 1.1455\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0134 - mean_squared_error: 1.5662 - val_loss: 0.8620 - val_mean_squared_error: 1.1210\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9995 - mean_squared_error: 1.5177 - val_loss: 0.8561 - val_mean_squared_error: 1.1100\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 1.0265 - mean_squared_error: 1.5797 - val_loss: 0.8372 - val_mean_squared_error: 1.0717\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9919 - mean_squared_error: 1.5199 - val_loss: 0.8300 - val_mean_squared_error: 1.0613\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9951 - mean_squared_error: 1.5260 - val_loss: 0.8121 - val_mean_squared_error: 1.0238\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.9701 - mean_squared_error: 1.4583 - val_loss: 0.8020 - val_mean_squared_error: 1.0047\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9718 - mean_squared_error: 1.4858 - val_loss: 0.7984 - val_mean_squared_error: 1.0041\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9613 - mean_squared_error: 1.4381 - val_loss: 0.7883 - val_mean_squared_error: 0.9826\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9594 - mean_squared_error: 1.4679 - val_loss: 0.7820 - val_mean_squared_error: 0.9709\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9643 - mean_squared_error: 1.4434 - val_loss: 0.7779 - val_mean_squared_error: 0.9623\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9565 - mean_squared_error: 1.4276 - val_loss: 0.7748 - val_mean_squared_error: 0.9572\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9552 - mean_squared_error: 1.4436 - val_loss: 0.7763 - val_mean_squared_error: 0.9597\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9373 - mean_squared_error: 1.3841 - val_loss: 0.7737 - val_mean_squared_error: 0.9538\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9468 - mean_squared_error: 1.4108 - val_loss: 0.7696 - val_mean_squared_error: 0.9449\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9471 - mean_squared_error: 1.4101 - val_loss: 0.7679 - val_mean_squared_error: 0.9407\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9426 - mean_squared_error: 1.3939 - val_loss: 0.7663 - val_mean_squared_error: 0.9371\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9285 - mean_squared_error: 1.3637 - val_loss: 0.7685 - val_mean_squared_error: 0.9404\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9327 - mean_squared_error: 1.3916 - val_loss: 0.7643 - val_mean_squared_error: 0.9314\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9508 - mean_squared_error: 1.4127 - val_loss: 0.7637 - val_mean_squared_error: 0.9302\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9241 - mean_squared_error: 1.3451 - val_loss: 0.7622 - val_mean_squared_error: 0.9262\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9376 - mean_squared_error: 1.3910 - val_loss: 0.7656 - val_mean_squared_error: 0.9339\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9360 - mean_squared_error: 1.3861 - val_loss: 0.7606 - val_mean_squared_error: 0.9220\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9403 - mean_squared_error: 1.4036 - val_loss: 0.7596 - val_mean_squared_error: 0.9210\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9210 - mean_squared_error: 1.3458 - val_loss: 0.7613 - val_mean_squared_error: 0.9255\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9261 - mean_squared_error: 1.3459 - val_loss: 0.7608 - val_mean_squared_error: 0.9245\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9324 - mean_squared_error: 1.3838 - val_loss: 0.7612 - val_mean_squared_error: 0.9233\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9335 - mean_squared_error: 1.3815 - val_loss: 0.7594 - val_mean_squared_error: 0.9206\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9261 - mean_squared_error: 1.3478 - val_loss: 0.7562 - val_mean_squared_error: 0.9107\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9230 - mean_squared_error: 1.3452 - val_loss: 0.7598 - val_mean_squared_error: 0.9202\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9262 - mean_squared_error: 1.3585 - val_loss: 0.7566 - val_mean_squared_error: 0.9146\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9099 - mean_squared_error: 1.3032 - val_loss: 0.7587 - val_mean_squared_error: 0.9197\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9226 - mean_squared_error: 1.3518 - val_loss: 0.7558 - val_mean_squared_error: 0.9131\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9152 - mean_squared_error: 1.3573 - val_loss: 0.7559 - val_mean_squared_error: 0.9128\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9210 - mean_squared_error: 1.3313 - val_loss: 0.7539 - val_mean_squared_error: 0.9062\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9161 - mean_squared_error: 1.3307 - val_loss: 0.7518 - val_mean_squared_error: 0.9021\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9243 - mean_squared_error: 1.3521 - val_loss: 0.7535 - val_mean_squared_error: 0.9090\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9155 - mean_squared_error: 1.3221 - val_loss: 0.7555 - val_mean_squared_error: 0.9114\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9117 - mean_squared_error: 1.3344 - val_loss: 0.7569 - val_mean_squared_error: 0.9152\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9238 - mean_squared_error: 1.3511 - val_loss: 0.7539 - val_mean_squared_error: 0.9099\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9162 - mean_squared_error: 1.3428 - val_loss: 0.7509 - val_mean_squared_error: 0.9028\n",
      "Epoch 85/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9094 - mean_squared_error: 1.3234 - val_loss: 0.7515 - val_mean_squared_error: 0.9043\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9105 - mean_squared_error: 1.3263 - val_loss: 0.7498 - val_mean_squared_error: 0.8976\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9124 - mean_squared_error: 1.3117 - val_loss: 0.7492 - val_mean_squared_error: 0.8976\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9350 - mean_squared_error: 1.3798 - val_loss: 0.7509 - val_mean_squared_error: 0.9002\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9166 - mean_squared_error: 1.3438 - val_loss: 0.7495 - val_mean_squared_error: 0.8998\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9013 - mean_squared_error: 1.2926 - val_loss: 0.7517 - val_mean_squared_error: 0.9033\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 1s 15ms/step - loss: 0.9261 - mean_squared_error: 1.3622 - val_loss: 0.7504 - val_mean_squared_error: 0.8993\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 1s 16ms/step - loss: 0.9087 - mean_squared_error: 1.3251 - val_loss: 0.7493 - val_mean_squared_error: 0.8993\n",
      "Epoch 93/150\n",
      "41/91 [============>.................] - ETA: 0s - loss: 0.9201 - mean_squared_error: 1.3818"
     ]
    }
   ],
   "source": [
    "# Hyperparameters:\n",
    "# Time step: 0.5s\n",
    "\n",
    "final_model = keras.models.Sequential([\n",
    "    TimeDistributed(LayerNormalization()),\n",
    "    TimeDistributed(conv_layer(input_shape=(1920, 20), filters=32, kernel_size=6)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=64)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=128)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(conv_layer(filters=128)),\n",
    "    TimeDistributed(pooling()),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(64),\n",
    "    Dense(128, activation=leaky_relu),\n",
    "    Dropout(0.3),\n",
    "    Dense(2)\n",
    "])\n",
    "\n",
    "X_final_train = np.concatenate([X_mfcc_train, X_mfcc_valid], axis=0)\n",
    "y_final_train = np.concatenate([y_train, y_valid], axis=0)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.000005)\n",
    "final_model.compile(loss='mae', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "history = final_model.fit(X_final_train, y_final_train, \n",
    "                    epochs=150,\n",
    "                    validation_data=(X_mfcc_test, y_test), \n",
    "                    batch_size=16, \n",
    "                    callbacks=early_stopping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = final_model.evaluate(X_mfcc_test, y_test)\n",
    "print(f'Final test reg RMSE: {list(map(math.sqrt, score))}')\n",
    "y_pred = final_model.predict(X_mfcc_test)\n",
    "\n",
    "cat_y_pred = categorize_val_arousal(y_pred)\n",
    "cat_y_test = categorize_val_arousal(y_test)\n",
    "\n",
    "accuracy = accuracy_score(cat_y_test, cat_y_pred)\n",
    "print(f'Final test Accuracy: {accuracy}')\n",
    "\n",
    "pd_y_actu = pd.Series(cat_y_test, name='Actual')\n",
    "pd_y_pred = pd.Series(cat_y_pred, name='Predicted')\n",
    "df_confusion = pd.crosstab(pd_y_actu, pd_y_pred)\n",
    "print(f'Final confusion matrix: \\n{df_confusion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
